# 协程

**协程，又称为微线程，是实现多任务的另一种方式。**只不过是比线程更小的一种执行单元。因为协程自带CPU的执行单元，只要在合适的时机，就可以从一个协程切换到另一个协程。

协程和线程的差异：

- 在执行多任务时，每个线程都有自己的缓存数据，操作系统还会进行数据的恢复，线程的切换非常消耗性能。
- 协程的切换只是单纯操作CPU的上下文

## yield实现生产者消费者模式

用来模拟协程之间的切换

其中,生产者用来启动生成器，消费者来执行生成器，生产者生产消息后，跳转到消费者执行消息，待消费者执行完毕后，回到生产者，继续生产消息

```python
def produce(c):
    print("--3、启动生成器，开始执行生成器consumer--")
    c.send(None)  # 3、启动生成器，开始执行生成器consumer
    print("--6、继续往下执行--")
    n = 0
    while n < 5:
        n += 1
        print("[Producer]: producing {} ..".format(n))
        print("--7、第{}次唤醒生成器，从yield位置继续往下执行！--".format(n + 1))
        r = c.send(n)  # 第二次唤醒生成器
        print('r的值是*******************************************************', r)
        print("--9、从第8步往下--")
        print("[Producer]: consumer return {} ..".format(r))

    c.close()


def consumer():
    print('--4、开始执行生成器代码--')
    response = None
    while True:
        print('--5、yield，中断，保存上下文--')
        n = yield response  # 4、yield，中断，保存上下文
        print('--8、获取上下文，继续往下执行--')
        if not n:
            return
        print("[Consumer]: consuming {} ..".format(n))
        response = "ok"


if __name__ == "__main__":
    c = consumer()  # 1、定义生成器，consumer并不执行
    produce(c)  # 2、运行produce函数
```

## 使用greenlet实现协程

greenlet已经实现了协程，但是需要人工进行切换，很麻烦

### greenlet实现不带参数的协程

```python
import time
from greenlet import greenlet


def g1():
    while True:
        print('this is a g1')
        g2.switch()
        time.sleep(1)


def g2():
    while True:
        print('this is a g2')
        g1.switch()
        time.sleep(1)


if __name__ == '__main__':
    g1 = greenlet(g1)
    g2 = greenlet(g2)
    g1.switch()
```

### greenlet实现带参数的协程

```python
def g3(name):
    while True:
        print(f'this is {name}')
        g4.switch('b')
        time.sleep(1)


def g4(name):
    while True:
        print(f'this is {name}')
        g3.switch()
        time.sleep(1)


if __name__ == '__main__':
    g3 = greenlet(g3)
    g4 = greenlet(g4)
    g3.switch('a')
```

## gevent实现协程

gevent比greenlet更加强大，能够自动切换任务，原理是当遇到一个IO(如:网络，文件操作)时，就会切换到其他协程,再在适当的时机切换回来。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。gevent是第三方库，通过greenlet实现coroutine,创建，调度的开销比线程小，程序内部的执行效率高。

gevent库实现了python标准库中一些阻塞库的非阻塞版本，如果socket,os,select，可以使用这些非阻塞库来替代python中的阻塞库。gevetn是基于协程的python网络库.

### **gevent的特点**

- 基于libev的快速事件循环(Linux上epoll，FreeBSD上kqueue）。
- 基于greenlet的轻量级执行单元。
- API的概念和Python标准库一致(如事件，队列)。
- 可以配合socket，ssl模块使用。
- 能够使用标准库和第三方模块创建标准的阻塞套接字(gevent.monkey)。
- 默认通过线程池进行DNS查询,也可通过c-are(通过GEVENT_RESOLVER=ares环境变量开启）。
- TCP/UDP/HTTP服务器
- 子进程支持（通过gevent.subprocess）
- 线程池

### **gevent常用方法**

```
gevent.spawn()	创建一个普通的Greenlet对象并切换
gevent.spawn_later(seconds=3)	延时创建一个普通的Greenlet对象并切换
gevent.spawn_raw()	创建的协程对象属于一个组
gevent.getcurrent()	返回当前正在执行的greenlet
gevent.joinall(jobs)	将协程任务添加到事件循环，接收一个任务列表
gevent.wait()	可以替代join函数等待循环结束，也可以传入协程对象列表
gevent.kill()	杀死一个协程
gevent.killall()	杀死一个协程列表里的所有协程
monkey.patch_all()	非常重要，会自动将python的一些标准模块替换成gevent框架
```

### **gevent常用实例对象方法**

```
from gevent import Greenlet  # 导入协程对象

# 创建协程实例
g = Greenlet(func_name, options)
```

```
Greentlet.spawn()  # 创建协程对象并启动
Greentlet.spawn_later(seconds=3)  # 延时启动
g.start()  # 协程启动
g.start_later(3)  # 延时启动
g.join()  # 等待任务完成
g.get  得到协程返回的值
g.dead() 判断协程是否死亡
g.kill() 杀死正在运行的协程并唤醒其他协程，这个协程将不会再执行
g.ready() 任务完成返回一个真值
g.successful() 任务完成返回真值，否则抛出异常
g.loop  获取时间循环对象
g.value  获取返回的值
g.exception 如果有错误信息，获取
g.exc_info 错误的详细信息
g.rawlink(back)  普通回调，将g作为回调函数的参数
g.unlink()  删除回调函数
g.link_value(back) 执行成功的回调函数
g.link_exception(back) 执行失败的回调函数
```

### **gevent.pool的特殊方法**

```
pool.wait_available():等待直到有一个协程有结果
pool.dd(greenlet):向进程池添加一个方法并跟踪，非阻塞
pool.discard(greenlet):停止跟踪某个协程
pool.start(greenlet):加入并启动协程
pool.join():阻塞等待结束
pool.kill():杀死所有跟踪的协程
pool.killone(greenlet):杀死一个协程
```

### 什么时候用gevent，什么时候不用

**gevent的优势**

- 可以通过同步的逻辑实现并发操作，大大降低了编写并行/并发程序的难度
- 在一个进程中使用 gevent 可以有效避免对 *临界资源* 的互斥访问

如果程序中涉及到较多的IO，可以使用gevent,但是

- gevent中coroutine【协同程序】的调用是由开发者决定的，而不是操作系统决定
- 主要解决的 是I/O问题
- 由于是在一个进程中实现协同程序，并且操作系统以进程为单位分配处理机资源【一个进程分配一个处理机资源】

gevent不适合在以下场景中使用

- 对任务延迟有要求的场景，如交互式程序中(需要操作系统公平调度)
- cpu计算任务
- 当需要运行多个进程时

## gevent生成协程实例

方法有两种

```
1. gevent.spawn()
2. 继承Greenlet父类
```

**注意：**

- 如果仅想生成协程实例并加入调度队列中，可以使用gevent.spawn()
- 如果生成协程实例，暂时不想加入调度，可以使用继承Greenlet的方式,之后若要加入调度队列中，需要调用start()方法

### **subclass Greenlet**

```python
import gevent
from gevent import Greenlet

"""
使用继承Greenlet方式生成协程实例，不会将任务自动加入调度队列，需要使用start方法手动加入
"""


class MyGevent(Greenlet):
    def __init__(self, timeout, msg):
        Greenlet.__init__(self)
        self.timeout = timeout
        self.msg = msg

    def _run(self):
        print(f'继承Greenlet{self.msg}')
        gevent.sleep(self.timeout)
        print(f'继承Greenlet结束')


class TestGevent:
    def __init__(self, timeout=1):
        self.timeout = timeout

    def run(self):
        # 创建协程实例
        g0 = gevent.spawn(self.tasks, 1, 'work')
        g1 = Greenlet.spawn(self.tasks, 2, 'run')
        g3 = MyGevent(self.timeout, 'eat')
        g3.start()  # 手动将协程任务加入调度队列

        gevent.joinall([g0, g1, g3])  # 将协程任务添加到事件循环
        print('tasks done')

    def tasks(self, pid, msg):
        """
        协程任务函数
        :param pid: 协程id
        :param msg: 协程信息
        :return:
        """
        print(f'this is task{pid}, want to{msg}')
        gevent.sleep(1)
        print(f'this task{pid}done')


if __name__ == '__main__':
    t = TestGevent()
    t.run()
```

```
https://blog.csdn.net/biheyu828/article/details/86593413
https://blog.csdn.net/weixin_41599977/article/details/93656042
```

### **从主线程切换到子线程的方法**

- 使用gevent.sleep()
- Greenlet或者Greenlet子类的实例的join()方法
- monkey patch的库或者方法
  - socket
  - ssl
  - os.fork
  - time.sleep
  - select.select
  - thread
  - subprocess
  - sys.stdin，sys.stdout，sys.stderr

### gevent核心功能

- Greenlet
- 同步和异步执行
- 确定性
- 创建Greenlet
- Greenlet状态
- 程序停止
- 超时
- 猴子补丁

```
在gevent中用到的主要模式是Greenlet, 它是以C扩展模块形式接入Python的轻量级协程。 Greenlet全部运行在主程序操作系统进程的内部，但它们被协作式地调度。

一个 “greenlet” 是一个小型的独立伪线程。可以把它想像成一些栈帧，栈底是初始调用的函数，而栈顶是当前greenlet的暂停位置。你使用greenlet创建一堆这样的堆栈，然后在他们之间跳转执行。跳转必须显式声明的：一个greenlet必须选择要跳转到的另一个greenlet，这会让前一个挂起，而后一个在此前挂起处恢复执行。不同greenlets之间的跳转称为切换(switching) 。
```

 **greenlet不是一种真正的并发机制，而是在同一线程内，在不同函数的执行代码块之间切换，实施“你运行一会、我运行一会”，并且在进行切换时必须指定何时切换以及切换到哪。**

**greenlet类主要有两个方法**

- switch():用来切换协程
- throw():用来抛出异常同时终止程序

```python
def test1(g, gr):
    for i in range(100):
        print('------- 协程A ---------')
        g.switch(gr, g)  # 手动切换协程
        time.sleep(1)


def test2(g, gr):
    s = 'afdjasfjsajdfasoifiiififififififiiaisiiifah'
    for i in s:
        print('------- 协程B ---------')
        g.switch(gr, g)  # 手动切换协程
        time.sleep(1)


if __name__ == '__main__':
    g1 = greenlet(test1)
    g2 = greenlet(test2)
    g1.switch(g2, g1)  # 手动进行协程的切换
```

#### greenlet方法

greenlet的状态通常是一个依赖于时间的参数：

- started – Boolean, 指示此Greenlet是否已经启动
- ready() – Boolean, 指示此Greenlet是否已经停止
- successful() – Boolean, 指示此Greenlet是否已经停止而且没抛异常
- value – 任意值, 此Greenlet代码返回的值
- exception – 异常, 此Greenlet内抛出的未捕获异常

**异步本质上是随机，异步部分的整体运行时间要比同步大大减少**

#### **同步和异步执行**

下面是另外一个多少有点人造色彩的例子，定义一个非确定性的(non-deterministic) 的`task`函数(给定相同输入的情况下，它的输出不保证相同)。 此例中执行这个函数的副作用就是，每次task在它的执行过程中都会随机地停某些秒。

```python
import gevent
import random
 
def task(pid):
    gevent.sleep(random.randint(0,2)*0.001)
    print('task {} done'.format(pid))
 
def synchronous():
    for i in range(5):
        task(i)
 
def asynchronous():
    gev_list = [gevent.spawn(task, i) for i in range(5)]
    gevent.joinall(gev_list)
 
print("synchronous:")
synchronous()
 
print("asynchronous:")
asynchronous()
```

**结果**

```python
synchronous:
task 0 done
task 1 done
task 2 done
task 3 done
task 4 done
asynchronous:
task 4 done
task 3 done
task 0 done
task 1 done
task 2 done
```

#### 确定性

greenlet具有确定性。在相同配置相同输入的情况下，它们总是会产生相同的输出。

下面是另外一个多少有点人造色彩的例子，定义一个非确定性的(non-deterministic) 的task函数(给定相同输入的情况下，它的输出不保证相同)。 此例中执行这个函数的副作用就是，每次task在它的执行过程中都会随机地停某些秒。

```python
import time
def echo(i):
    time.sleep(0.001)
    return i
# Non Deterministic Process Pool
from multiprocessing.pool import Pool
p = Pool(10)
run1 = [a for a in p.imap_unordered(echo, range(10))]
run2 = [a for a in p.imap_unordered(echo, range(10))]
run3 = [a for a in p.imap_unordered(echo, range(10))]
run4 = [a for a in p.imap_unordered(echo, range(10))]
print(run1 == run2 == run3 == run4)
# Deterministic Gevent Pool
from gevent.pool import Pool
p = Pool(10)
run1 = [a for a in p.imap_unordered(echo, range(10))]
run2 = [a for a in p.imap_unordered(echo, range(10))]
run3 = [a for a in p.imap_unordered(echo, range(10))]
run4 = [a for a in p.imap_unordered(echo, range(10))]
print(run1 == run2 == run3 == run4)
```

#### 程序停止

当主程序(main program)收到一个SIGQUIT信号时，不能成功做yield操作的 Greenlet可能会令意外地挂起程序的执行。这导致了所谓的僵尸进程， 它需要在Python解释器之外被kill掉。

通用的处理模式就是在主程序中监听SIGQUIT信号，调用gevent.shutdown退出程序。

#### 超时

通过超时可以对代码块儿或一个Greenlet的运行时间进行约束。

#### 猴子补丁

```
monkey.patch_all() 给所有的耗时操作打上补丁
协程遇到耗时操作，会自动切换到其他协程
```

## asyncio

**Python中使用协程最常用的库是asyncio**

#### 相关概念

- event_loop:事件循环。相当于一个无线循环，可以把一些函数注册到这个事件循环上，当条件满足时，就会进行相应的处理。
- coroutine对象：协程对象。只一个使用asyncio关键字定义的函数，它的函数调用不会立即执行，而是会返回一个协程对象.协程对象需要注册到事件循环中，由事件循环调用。
- task任务：一个协程对象就是一个原生可以挂起的函数，任务是对协程的进一步封装，其中包含任务的各种状态。
- future:代表将来执行或者没有执行的任务结果。它与task没有本质的区别。
- async/await关键字：python3.5用于定义协程的关键字，async定义一个协程，await用于挂起阻塞的异步调用接口

定义一个协程，使用async定义一个协程，协程是一个对象，不能直接运行，需要把协程放入事件循环中，在事件循环适当的适当的时候进行调用.asyncio.get_event_loop()方法可以创建一个事件循环，然后由run_until_complete(协程对象)将协程注册到事件循环中，启动事件循环

run_until_complete根据传递的参数的不同，返回的结果也有所不同

```
1、run_until_complete()传递的是一个协程对象或task对象，则返回他们finished的返回结果（前提是他们得有return的结果，否则返回None）
2、run_until_complete(asyncio.wait(多个协程对象或任务))，函数会返回一个元组包括（done, pending），通过访问done里的task对象，获取返回值
3、run_until_complete(asyncio.gather(多个协程对象或任务))，函数会返回一个列表，列表里面包括各个任务的返回结果，按顺序排列
```

python 3.7 以前的版本调用异步函数的步骤：

1、调用asyncio.get_event_loop()函数获取事件循环loop对象
2、通过不同的策略调用loop.run_forever()方法或者loop.run_until_complete()方法执行异步函数

```python
"""
使用async关键字定义一个协程对象
await用于挂起阻塞的异步调用接口
"""
import asyncio


async def fun():
    for i in range(10):
        print(f'this is {i}')
        await asyncio.sleep(1)  # 阻塞调用其他协程，但是当前只有一个协程，所以不会调用执行其他协程


coroutine = fun()  # 协程对象
if __name__ == '__main__':
    # 方式一
    loop = asyncio.get_event_loop()  # 创建事件循环
    loop.run_until_complete(coroutine)  # 将协程对象加入到事件循环中，并执行

    # 方式二  这是Python3.7以后的协程调用
    asyncio.run(coroutine)  # 创建一个新的事件循环，以coroutine为程序的入口，执行完毕后关闭事件循环
```

**创建一个task** 协程对象不能直接运行，在注册到事件循环的时候，其实是**run_until_complete方法将协程包装成一个task对象**，所谓的task对象就是Future类的子类，它保存了协程运行后的状态，用于未来获取协程的结果。

```python
import asyncio

"""
协程对象被创建以后不能直接运行，需要注册到事件循环，在注册到事件循环时，也就是将协程对象封装为一个task对象
task对象是Future对象的子类，保留了协程运行后的状态。用于未来获取协程的结果
"""


async def fun():
    for i in range(10):
        print(i)


coroutine = fun()

loop = asyncio.get_event_loop()  # 创建事件循环
task = loop.create_task(coroutine)  # 创建一个task
# task = asyncio.ensure_future(coroutine)  # 这样也可以创建一个task
print('运行前task----->', task)
loop.run_until_complete(task)  # run_until_complete方法接受的是一个task对象或者协程对象,返回finished后的结果
print('运行后task----->', task)

print(isinstance(task, asyncio.Future))  # isinstance()判断一个对象是否是一个已知类型,返回值为boolean
```

isinstance与type的区别

```
type不会认为子类是一种父类类型，不会考虑继承关系
isinstance会认为子类是一种父类类型，考虑继承关系
```

#### 绑定回调

**绑定回调** 在task执行完毕的时候可以获取执行的结果，回调的最后一个参数是future对象，通过这个对象可以获取协程的返回值，如果回调函数需要多个参数，可以通过偏函数导入。创建的task和回调里面的future对象其实是同一个对象。

```python
import asyncio
from functools import partial

"""
回调的最后一个参数是future对象，通过这个对象可以获取协程的返回值，如果回调函数需要传递多个参数，可以使用偏函数
"""


async def func(x):
    for i in range(3):
        print(f'work is {x}')
    return f'work finished {x}'


# 定义一个回调函数
def call_back(future):
    print(f'Call back:{future.result()}')


coroutine = func(1)

# 创建事件循环
loop = asyncio.get_event_loop()
# 创建task对象
task = asyncio.ensure_future(coroutine)
# task对象添加回调函数
task.add_done_callback(call_back)
# 事件循环执行
loop.run_until_complete(task)  # 返回后的结果
```

**在不绑定回调函数的时候，当task处于finished的状态时，可以直接读取task的result的值**

```python
import asyncio
from functools import partial

"""
回调的最后一个参数是future对象，通过这个对象可以获取协程的返回值，如果回调函数需要传递多个参数，可以使用偏函数
"""
async def func(x):
    for i in range(3):
        print(f'work is {x}')
    return f'work finished {x}'


coroutine = func(1)

# 创建事件循环
loop = asyncio.get_event_loop()
# 创建task对象
task = asyncio.ensure_future(coroutine)
# task对象添加回调函数
# 事件循环执行
loop.run_until_complete(task)  # 返回后的结果
print(task.result())
```

阻塞和await使用async可以创建协程对象，使用await可以对正在耗时的操作挂起。就像生成器中的yield一样，函数让出控制权。协程遇到await，事件循环会挂起这个协程，执行别的协程，直到其他协程执行完毕或者挂起，再执行下一个协程。

如果一个对象可以使用await，那么这个对象就是可等待对象。

**耗时操作一般指IO操作：** 网络请求，文件读取等，使用asyncio.sleep模拟耗时操作。协程的目的也是让这些IO操作异步化。

#### 并发运行任务

asyncio.gather（* aws，loop = None，return_exceptions = False ） 同时在aws 序列中运行等待对象。

- 如果在aws中等待的是协程，它将自动调度为任务。
- 如果所有等待都成功完成，则结果是返回值的汇总列表。结果值的顺序对应于aws中的等待顺序。
- 如果return_exceptions是False（默认），则第一个引发的异常会立即传播到等待的任务gather()。aws序列 中的其他等待项将不会被取消并继续运行。
- 如果return_exceptions是True，异常的处理方式一样成功的结果，并在结果列表汇总。
- 如果gather()被取消，所有提交的awaitables（尚未完成）也被取消。
  如果aws序列中的任何任务或未来被取消，则将其视为已引发CancelledError- 在这种情况下不会取消gather() 呼叫。这是为了防止取消一个提交的任务/未来以导致其他任务/期货被取消。

#### 屏蔽取消操作

asyncio.shield(aw, * , loop=None) 保护一个 可等待对象 防止其被 取消。如果 aw 是一个协程，它将自动作为任务加入日程。

res = await shield(something()) 相当于: res = await something()

不同之处 在于如果包含它的协程被取消，在 something() 中运行的任务不会被取消。从 something() 的角度看来，取消操作并没有发生。然而其调用者已被取消，因此 “await” 表达式仍然会引发 CancelledError。

- 如果通过其他方式取消 something() (例如在其内部操作) 则 shield() 也会取消。
- 如果希望完全忽略取消操作 (不推荐) 则 shield() 函数需要配合一个 try/except 代码段，如下所示:

```python
try:
    res = await shield(something())
except CancelledError:
    res = None
```

#### 超时

```
asyncio.wait_for(aw, timeout, * , loop=None) 等待 aw 可等待对象 完成，指定 timeout 秒数后超时。

如果 aw 是一个协程，它将自动作为任务加入日程。
timeout 可以为 None，也可以为 float 或 int 型数值表示的等待秒数。如果 timeout 为 None，则等待直到完成。
    如果发生超时，任务将取消并引发 asyncio.TimeoutError.
    要避免任务 取消，可以加上 shield()。函数将等待直到目标对象确实被取消，所以总等待时间可能超过 timeout 指定的秒数。如果等待被取消，则 aw 指定的对象也会被取消。
loop 参数已弃用，计划在 Python 3.10 中移除。
```

#### 简单等待

```
简单等待：
asyncio.wait（aws，* , loop = None，timeout = None，return_when = ALL_COMPLETED ） 同时运行aws中的等待对象 并阻塞 ，直到return_when指定的条件。
返回两组tasks/futures：（done，pending）
用法：done, pending = await asyncio.wait(aws)
return_when 指定此函数应在何时返回。它必须为以下常数之一:
    FIRST_COMPLETED 函数将在任意可等待对象结束或取消时返回。
    FIRST_EXCEPTION 函数将在任意可等待对象因引发异常而结束时返回。当没有引发任何异常时它就相当于 ALL_COMPLETED。
    ALL_COMPLETED 函数将在所有可等待对象结束或取消时返回。与 wait_for() 不同，wait() 在超时发生时不会取消可等待对象。
```

asyncio.as_completed(aws, * , loop=None, timeout=None) 并发地运行 aws 集合中的 可等待对象。**返回一个 Future 对象的迭代器**。返回的每个 Future 对象代表来自剩余可等待对象集合的最早结果。

如果在所有 Future 对象完成前发生超时则将引发 asyncio.TimeoutError。

```
asyncio.wait(tasks)接受一个task列表  执行的顺序与列表里的任务顺序有关
asyncio.gather(*tasks) 接受一堆tasks，tasks也可以是一个列表，使用*解包
asyncio.as_completed 返回一个迭代器，每次返回最先完成的结果
await:可以等待一个协程，也可以启动一个协程
asyncio.create_task() 函数用来并发运行作为 asyncio 任务 的多个协程
可等待对象： 如果一个对象可以在 await 语句中使用，那么它就是 可等待 对象。许多 asyncio API 都被设计为接受可等待对象。
可等待 对象有三种主要类型: 协程, 任务 和 Future .
协程：python中的协程属于 可等待 对象，所以可以在其他协程中被等待
Future对象 Future 是一种特殊的 低层级 可等待对象，表示一个异步操作的 最终结果。当一个 Future 对象 被等待，这意味着协程将保持等待直到该 Future 对象在其他地方操作完毕
```

#### asyncio模块爬取小说，图片

Python使用asyncio模块进行异步操作，但是在进行请求时，需要使用aiohttp来进行异步请求，使用aiofiles来进行异步存储文件。这两个模块都是第三方模块，需要进行安装

```python
pip install aiohttp
pip install aiofiles
```

**异步进行发送请求**

assert关键字用来进行断言，如果为True，则继续向下执行；如果为False，则会抛出异常，也可以自定义异常

```python
async def get_index():
    """
    获取首页
    首页url: https://www.ku66.net/r/2/index.html
    :return:
    """
    url = 'https://www.ku66.net/r/2/index.html'
    async with aiohttp.ClientSession() as session:
        async with await session.get(url=url, headers=headers) as response:
            code = response.status
            assert code == 200, '状态码不为200'
            html = await response.text()
            return html
```

**异步存储文件**

```python
async with aiofiles.open('path', 'w') as file:
	await file.write('')
```

#### 进度条的使用

Python中可以对下载的文件设置进度条

需要安装第三方模块

```
pip install tqdm
```

使用

```python
from tqdm import tqdm

# 方法一:传递一个列表
bar = tqdm(list类型)
for leeter in bar:
    bar.set_description(leeter)
    
# 传递任意一个字符
import time
from tqdm import tqdm, trange

for i in trange('传递的字符'):
    print('内容')
    time.sleep(1)
```

#### 线程池和进程池

系统启动一个新线程的成本是比较高的，因为它涉及与操作系统的交互。在这种情形下，使用线程池可以很好地提升性能，尤其是当程序中需要创建大量生存期很短暂的线程时，更应该考虑使用线程池。**线程池在系统启动时即创建大量空闲的线程**，**程序只要将一个函数提交给线程池，线程池就会启动一个空闲的线程来执行它。当该函数执行结束后，该线程并不会死亡，而是再次返回到线程池中变成空闲状态，等待执行下一个函数。**此外，使用线程池可以有效地控制系统中并发线程的数量。当系统中包含有大量的并发线程时，会导致系统性能急剧下降，甚至导致 Python 解释器崩溃，**而线程池的最大线程数参数可以控制系统中并发线程的数量不超过此数。**

线程池的基类是 concurrent.futures 模块中的 Executor，Executor 提供了两个子类，即 ThreadPoolExecutor 和 ProcessPoolExecutor，其中 ThreadPoolExecutor 用于创建线程池，而 ProcessPoolExecutor 用于创建进程池。

如果使用线程池/进程池来管理并发编程，那么只要将相应的 task 函数提交给线程池/进程池，剩下的事情就由线程池/进程池来搞定。

```
Exectuor 提供了如下常用方法：
	submit(fn, *args, **kwargs)：将 fn 函数提交给线程池。*args 代表传给 fn 函数的参数，*kwargs 代表以关键字参数的形式为 fn 函数传入参数。
	map(func, *iterables, timeout=None, chunksize=1)：该函数类似于全局函数 map(func, *iterables)，只是该函数将会启动多个线程，以异步方式立即对 iterables 执行 map 处理。线程池中的map方法会给可迭代对象中的每一个元素开启一个线程，并发的执行，相当于启动了len(可迭代对象)个线程
	shutdown(wait=True)：关闭线程池。
```

程序将 task 函数提交（submit）给线程池后，submit 方法会返回一个 Future 对象，Future 类主要用于获取线程任务函数的返回值。由于线程任务会在新线程中以异步方式执行，因此，线程执行的函数相当于一个“将来完成”的任务，所以 Python 使用 Future 来代表。

```
Future 提供了如下方法：
1. cancel()：取消该 Future 代表的线程任务。如果该任务正在执行，不可取消，则该方法返回 False；否则，程序会取消该任务，并返回 True。
2. cancelled()：返回 Future 代表的线程任务是否被成功取消。
3. running()：如果该 Future 代表的线程任务正在执行、不可被取消，该方法返回 True。
4. done()：如果该 Funture 代表的线程任务被成功取消或执行完成，则该方法返回 True。
5. result(timeout=None)：获取该 Future 代表的线程任务最后返回的结果。如果 Future 代表的线程任务还未完成，该方法将会阻塞当前线程，其中 timeout 参数指定最多阻塞多少秒。
6. exception(timeout=None)：获取该 Future 代表的线程任务所引发的异常。如果该任务成功完成，没有异常，则该方法返回 None。
7. add_done_callback(fn)：为该 Future 代表的线程任务注册一个“回调函数”，当该任务成功完成时，程序会自动触发该 fn 函数。
```

在用完一个线程池后，应该调用该线程池的 shutdown() 方法，该方法将启动线程池的关闭序列。**调用 shutdown() 方法后的线程池不再接收新任务，但会将以前所有的已提交任务执行完成。**当线程池中的所有任务都执行完成后，该线程池中的所有线程都会死亡。

```
使用线程池来执行线程任务的步骤如下：
    1. 调用 ThreadPoolExecutor 类的构造器创建一个线程池。
    2. 定义一个普通函数作为线程任务。
    3. 调用 ThreadPoolExecutor 对象的 submit() 方法来提交线程任务。
    4. 当不想提交任何任务时，调用 ThreadPoolExecutor 对象的 shutdown() 方法来关闭线程池。
```

##### 使用线程池

```python
"""
Python中使用concurrent.futures中的ThreadPoolExecutor来创建线程池
线程池创建的步骤：
    ① 调用ThreadPoolExecutor函数来创建一个线程池
    ② 定义一个普通函数作为任务
    ③ 调用ThreadPoolExecutor对象中的submit()方法将线程任务提交到线程池
    ④ 不想提交线程任务，调用ThreadPoolExecutor对象中的shutdown()方法关闭线程池
"""
import threading
import time
from concurrent.futures import ThreadPoolExecutor


def task(max_sum):
    """
    定义一个线程任务函数
    :return:
    """
    my_sum = 0
    for i in range(max_sum):
        print(threading.current_thread().getName() + ' ' + str(i))
        my_sum += 1
    return my_sum


if __name__ == '__main__':
    # 创建线程池  包含4个线程
    pool = ThreadPoolExecutor(max_workers=4)

    # 向线程池中提交任务  调用submit方法
    future1 = pool.submit(task, 50)  # submit方法会返回一个future对象 这个future对象代表的是将来要执行的任务

    # 向线程池中再次提交一个任务
    future2 = pool.submit(task, 100)

    # 判断任务是否执行完成 使用done方法  如果执行完成，返回True
    print(future1.done())
    print('------------------')
    time.sleep(3)
    print(future2.done())

    # 查看线程任务返回的结果
    print(future1.result())
    print('*************************')
    print(future2.result())

    # 关闭线程池
    pool.shutdown()
```

##### 线程池使用回调函数

```python
# @Author:hu
# @Time:2021/8/30 12:17 
# @File:线程池调用会回调函数.py
# @Software: PyCharm
import time
import threading
from concurrent.futures import ThreadPoolExecutor


def task(max_num):
    """
    定义一个线程任务
    :param max_num:
    :return:
    """
    my_num = 0
    for i in range(max_num):
        print(threading.current_thread().getName() + ' ' + str(i))
        my_num += i
    return my_num


# 使用上下文管理创建线程池
with ThreadPoolExecutor(max_workers=4) as pool:
    # 提交任务到线程池
    future1 = pool.submit(task, 50)
    future2 = pool.submit(task, 100)


    # 定义一个回调函数
    def get_result(future):
        print(future.result())


    # 为future1添加回调函数
    future1.add_done_callback(get_result)
    print('----------------------')
    future2.add_done_callback(get_result)
```

##### 线程池使用map

```python
# @Author:hu
# @Time:2021/8/30 13:48 
# @File:线程池使用map方法.py
# @Software: PyCharm
"""
线程池中的map方法会给可迭代对象中的每一个元素开启一个线程，并发的执行，相当于启动了len(可迭代对象)个线程
"""
import time
import threading
from concurrent.futures import ThreadPoolExecutor


def task(max_num):
    """
    定义一个线程任务
    :param max_num:
    :return:
    """
    my_num = 0
    for i in range(max_num):
        print(threading.current_thread().getName() + ' ' + str(i))
        my_num += 1
    return my_num


with ThreadPoolExecutor(max_workers=4) as pool:
    results = pool.map(task, (50, 100, 40))
    print('--------------')
    for result in results:
        print(result)
```

##### 使用进程池

Python中创建进程池的方式，一种是使用multiprocessing.Pool,一种是使用ProcessPoolExecutor

首先需要安装一个模块psutil

这个模块用来进行获取系统中的进程信息

```
pip install psutil
```

**multiprocessing.Pool实现进程池**

```python
import psutil
import os 
porcess = psutil.Process(os.getpid()) # os.getpid() 获取当前进程
print(process.name())  # process.name 当前进程的名字
print(process.pid)  #当前进程的id
```

```python
import multiprocessing  # 进程模块
import psutil  # 获取系统进程信息
import os



def task(max_num):
    """
    定义一个进程任务
    :param max_num:
    :return:
    """
    my_num = 0
    for i in range(max_num):
        pu = psutil.Process(os.getpid())
        print(f'当前进程名字为：{multiprocessing.current_process()}, id为：{pu.pid}')
        my_num += 1
    return my_num


if __name__ == '__main__':
    pool = multiprocessing.Pool(processes=3)
    for _ in range(4):
        pool.apply_async(task, (50,))

    pool.close()
    pool.join()
```

**ProcessPoolExecutor实现进程池**

```python
import psutil  # 获取系统进程信息
import os
from concurrent.futures import ProcessPoolExecutor  # 进程池


def task(max_num):
    """
    定义一个进程任务
    :param max_num:
    :return:
    """
    my_num = 0
    for i in range(max_num):
        pu = psutil.Process(os.getpid())
        print(f'当前进程名字为：{multiprocessing.current_process()}, id为：{pu.pid}')
        my_num += 1
    return my_num
    
if __name__ == '__main__':
    with ProcessPoolExecutor(max_workers=4) as pool:
        pool.submit(task, 50)
        pool.submit(task, 60)
        pool.submit(task, 70)
        pool.submit(task, 80)
        pool.submit(task, 80)
        pool.submit(task, 80)
```

